################################
#Case Studies  Interview
#===============================
library(xlsx)
library(mnormt)
library(psych)
library(GPArotation)
library(corrplot)

setwd("C:/Users/acer/Desktop/R Class Assignment/R part 2 assignments/6Case Study for Cluster and Factor Analysis/Case 3")
data<-read.xlsx("interview.xlsx",sheetIndex = 1)

View(data)
#No need to scale data as it already stndardised
dim(data)#48 16
data=data[-1]#dropping insignicant data

#creating correlation matrix
cordata<-cor(data);cordata
corrplot(corr = cordata,order = "hclust", tl.col='black', tl.cex=.75)

#creating eigen value 
# A factor is important if its eigenvalue is greater than 1 - Kaiser's Rule
eigen(cordata)$values
# [1] 7.76331118 2.07200466 1.45657481 1.31065725 0.91265216 0.64171228 0.37274769 0.34612400
# [9] 0.30898325 0.25239633 0.16425591 0.13844449 0.09012519 0.08294801 0.05162302 0.03543977
#4 factors can be created on data

#Get Screeplot
plot(eigen(cordata)$values,type="b")

#install.packages("psy")
library(psy)
scree.plot(cordata)


#factor analysis
faSol<-fa(cordata, nfactors = 4,fm = "pa",rotate = "oblimin")

#Visualisaion
fa.diagram(faSol)

summary(faSol)
faSol
#                                 PA1   PA2   PA3   PA4   h2    u2 com
# Form.of.letter.of.application -0.02  0.72  0.04 -0.18 0.55 0.447 1.1      PA2
# Appearance                     0.37  0.09  0.25  0.11 0.31 0.686 2.1  PA1  - Low weight    
# Academic.ability               0.06  0.19  0.08  0.69 0.51 0.491 1.2              PA4
# Likeability                   -0.05  0.15  0.87 -0.10 0.83 0.175 1.1          PA3
# Self.confidence                0.99 -0.26 -0.02 -0.04 0.87 0.130 1.1  PA1
# Lucidity                       0.83 -0.02  0.13  0.02 0.78 0.218 1.0  PA1
# Honesty                        0.09 -0.32  0.81  0.02 0.70 0.298 1.3          PA3
# Salesmanship                   0.93  0.11 -0.09 -0.06 0.88 0.125 1.1  PA1
# Experience                    -0.05  0.83 -0.06  0.11 0.67 0.335 1.1      PA2
# Drive                          0.73  0.25  0.01 -0.07 0.75 0.255 1.2  PA1
# Ambition                       0.95  0.03 -0.10 -0.06 0.87 0.134 1.0  PA1
# Grasp                          0.74  0.15  0.22  0.14 0.85 0.155 1.4  PA1
# Potential                      0.63  0.24  0.35  0.23 0.91 0.092 2.2  PA1
# Keeness.to.join                0.23  0.24  0.41 -0.63 0.96 0.041 2.4              PA4
# Suitability                    0.23  0.76  0.00  0.01 0.76 0.243 1.2      PA2
# 
#                       PA1  PA2  PA3  PA4
# SS loadings           5.57 2.43 2.14 1.04
# Proportion Var        0.37 0.16 0.14 0.07
# Cumulative Var        0.37 0.53 0.68 0.75   #above 0.5 so model can be selected
# Proportion Explained  0.50 0.22 0.19 0.09
# Cumulative Proportion 0.50 0.72 0.91 1.00
# 
# With factor correlations of 
#       PA1   PA2   PA3   PA4
# PA1  1.00  0.35  0.47 -0.11
# PA2  0.35  1.00  0.20 -0.02
# PA3  0.47  0.20  1.00 -0.16
# PA4 -0.11 -0.02 -0.16  1.00
# 
# Mean item complexity =  1.4
# Test of the hypothesis that 4 factors are sufficient.
# 
# The degrees of freedom for the null model are  105  and the objective function was  15.68
# The degrees of freedom for the model are 51  and the objective function was  2.24 
# 
# The root mean square of the residuals (RMSR) is  0.03 
# The df corrected root mean square of the residuals is  0.04 
# 
# Fit based upon off diagonal values = 1
# Measures of factor score adequacy             
#                                                   PA1  PA2  PA3  PA4
# Correlation of (regression) scores with factors   0.99 0.94 0.95 0.97
# Multiple R square of scores with factors          0.98 0.89 0.91 0.94
# Minimum correlation of possible factor scores     0.95 0.79 0.82 0.88


faSol$uniquenesses
# Form.of.letter.of.application   Appearance              Academic.ability 
# 0.44711589                    0.68601590                    0.49149938 
# Likeability               Self.confidence                      Lucidity 
# 0.17491715                    0.13016953                    0.21805963 
# Honesty                  Salesmanship                    Experience 
# 0.29832427                    0.12461456                    0.33487864 
# Drive                      Ambition                         Grasp 
# 0.25455453                    0.13374372                    0.15491364 
# Potential               Keeness.to.join                   Suitability 
# 0.09157438                    0.04115176                    0.24305311

#Appearance has high uniqueness
#Next are Academic Ability and Form of letter of application

faSol$communality
#Appearance has 0.31, just above par of 0.3

################                 Visulaization

### Plot loadings against one another
load = faSol$loadings[,1:4]
plot(load, type="n") # set up plot 
text(load,labels=names(data),cex=.7) # add variable names
#Since there are more than 2  factors so the plot wont be very communicative

########## Creating composite variables

conf = rowMeans(cbind(data$Self.confidence,data$Ambition,data$Salesmanship,data$Lucidity,
                      data$Grasp,data$Drive,data$Potential))
xp = rowMeans(cbind(data$Experience,data$Suitability,data$Form.of.letter.of.application))
honesty = rowMeans(cbind(data$Honesty,data$Likeability))
academic = rowMeans(cbind(data$Academic.ability,data$Keeness.to.join))
look<-data$Appearance
combined_data = cbind(conf,xp,honesty,academic,look)
combined_data = as.data.frame(combined_data)
View(combined_data)
eigen(cor(combined_data))$values

result2<-factanal(combined_data, factors = 2,na.action=na.omit)

################                 Visulaization

### Plot loadings against one another
load = result2$loadings[,1:2]
plot(load, type="n") # set up plot 
text(load,labels=names(data),cex=.7) # add variable names


#Loading factors into new dataset
new_data<-data.frame(factor.scores(data,faSol)$scores)
dim(new_data)


colnames(new_data)<-c("Self_Confidence", "Exp","Honesty","Academic")
head(new_data)
weight<-c(0.3,0.3,0.3,0.1)
new_data$score<-new_data[,1]*weight[1]+
  new_data[,2]*weight[2]+
  new_data[,3]*weight[3]+
  new_data[,4]*weight[4]

View(new_data)
new_data_sorted<-new_data[order(-new_data[,5]),]
top5<-new_data_sorted[0:5,]
top5
#So these guys can be sortlisted 


#Analysis after Dropping Appearance
ndata<-data[-2]
View(ndata)
eigen(cor(ndata))$values#4factors
ncor<-cor(ndata)
sol<-factanal(ndata,factors = 4,na.action = na.omit())
sol


fa(ncor,nfactors =4)
fa.diagram(fa(ncor,nfactors=4))

sol$uniquenesses

fscore<-factor.scores(ndata,sol)
fscore$scores
nnew_data<-as.data.frame(fscore$scores)
names(nnew_data)<-c("Confidence","Experience","Honesty","Academic")
View(nnew_data)

weight<-c(0.3,0.3,0.3,0.1)
nnew_data$score<-nnew_data[,1]*weight[1]+
  nnew_data[,2]*weight[2]+
  nnew_data[,3]*weight[3]+
  nnew_data[,4]*weight[4]

View(nnew_data)
nnew_data_sorted<-nnew_data[order(-nnew_data[,5]),]
top6<-new_data_sorted[0:6,]
top6
#Same result, 
